# ğŸŒ Environmental Prediction Models using Machine Learning

This project explores predictive modeling across three key environmental datasetsâ€”**Air Quality**, **Weather Data**, and **COâ‚‚ Emissions**â€”using various machine learning regression techniques. It forms part of the MSc in Data Analytics at the National College of Ireland.

---

## ğŸ‘©â€ğŸ’» Author

**Jayashree Rajkumar**  


---

## ğŸ“˜ Project Title

**Prediction of Air Quality, Weather Data, and COâ‚‚ in Air using Machine Learning Models**

---

## ğŸ¯ Objective

To evaluate the performance of multiple machine learning regression modelsâ€”Random Forest, Gradient Boosting, Support Vector Regression (SVR), Ridge Regression, and Neural Networksâ€”on environmental datasets and determine the most accurate model based on MSE, RMSE, and RÂ² metrics.

---

## ğŸ“Š Datasets Used

1. **Air Quality Dataset** â€“ 16,219 rows, 11 columns  
2. **Weather Dataset** â€“ 86,504 rows, 12 columns  
3. **COâ‚‚ Emissions Dataset** â€“ 25,205 rows, 35 columns

---

## ğŸ§  Models Implemented

- Random Forest Regression
- Gradient Boosting Regression
- Support Vector Regression (SVR)
- Ridge Regression
- Neural Network Regression (for Weather data)

---

## ğŸ§ª Methodology

The **KDD (Knowledge Discovery in Databases)** process was followed:

1. Data Collection
2. Data Cleaning & Preprocessing
3. Exploratory Data Analysis (EDA)
4. Correlation Analysis
5. Model Training using train/test split
6. Evaluation using:
   - Mean Squared Error (MSE)
   - Root Mean Squared Error (RMSE)
   - RÂ² Score

---

## ğŸ“ˆ Results Summary

| Dataset     | Best Model          | RÂ² Score | Notes |
|-------------|---------------------|----------|-------|
| Air Quality | Random Forest       | ~0.99    | High accuracy and low RMSE |
| Weather     | Random Forest       | ~0.98    | Best overall performer |
| COâ‚‚ Emissions | Random Forest    | ~0.95    | Most reliable prediction |

> Gradient Boosting also performed competitively across all datasets, while Ridge and SVR performed less consistently.

---

## ğŸ”® Future Work

- Advanced feature engineering to improve model performance
- Hyperparameter tuning for all models
- Application of ensemble techniques (e.g., stacking)
- Interpretability using SHAP/LIME
- Expansion with additional environmental datasets

---

## ğŸ› ï¸ Technologies & Libraries

- Python
- Scikit-learn
- Pandas & NumPy
- Matplotlib & Seaborn
- Jupyter Notebook

---



